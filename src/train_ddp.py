# -*- coding: utf-8 -*-
"""RAHF_train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n8Bug-l4fVCAXA7kLDJmhbKkN52jIsXm
"""
import json
import logging
import os
import sys
import time

import numpy as np
import torch
import torch.distributed as dist
import torch.nn as nn
import wandb
import yaml
from torch.cuda.amp import autocast, GradScaler
from torch.optim.lr_scheduler import CosineAnnealingLR
from torch.utils.data import DataLoader
from configs import get_args, VALID_SCORES
import random

sys.path.append('../')
from metrics import metric_cal_online
from criterions import MaskLoss, ScoreLoss
from dataset import RAHFDatasetCustom
from model.model_final import build_preprocessing_and_model
from utils import print_log_iter, save_in_training, final_save, print_trainable_params
from utils import ddp_print as print
from tqdm import tqdm

logger = logging.getLogger()


def set_params_trainable(model, args, stage='train'):
    if stage == 'warmup':
        if args.model == 'altclip':
            model.module.image_encoder.freeze()
            model.module.text_encoder.freeze()
        elif args.model == 'florence2':
            for param in model.module.florence2.parameters():
                param.requires_grad = False
    elif stage == 'train':
        if args.model == 'altclip':
            model.module.image_encoder.unfreeze()
            model.module.text_encoder.unfreeze()
        elif args.model == 'florence2':
            for name, param in model.module.named_parameters():
                if 'lora' in name:  # or 'vision_tower' in name:
                    param.requires_grad = True
        for name in args.freeze_params:
            for param in model.module.named_parameters():
                if name in param[0]:
                    param[1].requires_grad = False
        for name in args.unfreeze_params:
            for param in model.module.named_parameters():
                if name in param[0]:
                    param[1].requires_grad = True
    if dist.get_rank() == 0: print_trainable_params(model)


@torch.no_grad()
def evaluate(model, dataloader, device, criterion, iter_counter, prefix='val', log_flag=True,
             threshold_list=None):
    if threshold_list is None:
        threshold_list = [0, 5, 10, 20, 30, 40, 50, 60, 70, 80, 85, 90, 95, 100, 105, 110]
    model.eval()
    loss_heatmap_im, loss_score_im, loss_heatmap_mis, loss_score_mis = 0, 0, 0, 0
    preds = {}
    gts = {}
    count = 0
    with torch.no_grad():
        for inputs, targets in tqdm(dataloader, total=len(dataloader), desc=f'{prefix} evaluation'):
            count += 1
            inputs = inputs.to(device)
            outputs_im = model(inputs['pixel_values'].squeeze(1), inputs['input_ids'][:, 0, :])  # implausibility
            output_heatmap, target_heatmap = outputs_im[0].to(device), targets['artifact_map'].float().to(device)
            output_score, target_score = outputs_im[1].to(device), targets['artifact_score'].float().to(device)
            # get score
            if output_score.shape[-1] > 1:
                output_score = output_score.softmax(dim=-1)
                # weight sum
                output_score = torch.sum(
                    output_score * torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]).cuda(), dim=-1)
                output_score = (output_score - 1.) / 12.
            # set to mse
            # cur_loss_heatmap_im = criterion(output_heatmap, target_heatmap).item()
            loss_heatmap_im += torch.nn.MSELoss()(output_heatmap, target_heatmap).item()
            loss_score_im += torch.nn.MSELoss()(output_score, target_score).item()

            # if targets['img_name'][0].startswith('finetune'):  # check finetune data loss
            #     print(f"{targets['img_name']} artifact loss: {cur_loss_heatmap_im}")

            img_names = targets['img_name']

            for idx, img_name_item in enumerate(img_names):
                format_list = ['.jpg', '.png', '.jpeg', '.JPG', '.PNG', '.JPEG', '.bmp', '.BMP']
                for format in format_list:
                    if img_name_item.endswith(format):
                        img_name_item = img_name_item.split(format)[0]
                        break
                preds[img_name_item] = {
                    'pred_area': np.squeeze(np.uint8(output_heatmap[idx].cpu().numpy() * 255)),
                    'score': output_score[idx].item(),
                }
                gts[img_name_item] = {
                    'pred_area': np.squeeze(np.uint8(target_heatmap[idx].cpu().numpy() * 255)),
                    'score': target_score[idx].item(),
                }
        scale_factor = (255 ** 2, 4)
        # scale_factor = (255 ** 2, 1.)

    metrics_all = {}

    final_scores = {}
    for threshold in threshold_list:
        metrics = metric_cal_online(preds, gts, pred_mask_threshold=threshold)
        for key, value in metrics.items():
            if key == 'final_score':
                final_scores[threshold] = value
            if 'plcc' not in key.lower() and 'srcc' not in key.lower():
                key = f'{key}_{threshold}'
            key = f'{prefix}_{key}'
            metrics_all[key] = value
    best_threshold = max(final_scores, key=final_scores.get)
    metrics_all[f'{prefix}_best_threshold'] = best_threshold
    metrics_all[f'{prefix}_best_final_score'] = final_scores[best_threshold]
    # log
    val_loss = [loss_heatmap_im / len(dataloader) * scale_factor[0], loss_score_im / len(dataloader) * scale_factor[1],
                loss_heatmap_mis / len(dataloader), loss_score_mis / len(dataloader) * scale_factor[1]]
    if dist.get_rank() == 0 and log_flag:
        wandb.log(metrics_all, step=iter_counter)
        logger.info(json.dumps(metrics_all, indent=4))
        logger.info(f'{prefix}...')
        logger.info(f"Iteration {iter_counter} Validation:\n"
                    f"Implausibility Heatmap Loss = {val_loss[0]}, Implausibility Score Loss = {val_loss[1]}\n"
                    f"Sematic Heatmap Loss = {val_loss[2]}, Misalignment Score Loss = {val_loss[3]}")
        wandb.log({f'{prefix}_heatmap_loss': val_loss[0], f'{prefix}_score_loss': val_loss[1]}, step=iter_counter)
    model.train()
    return metrics_all, preds


def main(args):
    # set seed
    torch.manual_seed(args.seed)
    torch.cuda.manual_seed(args.seed)
    torch.cuda.manual_seed_all(args.seed)
    np.random.seed(args.seed)
    random.seed(args.seed)
    torch.backends.cudnn.deterministic = True

    dist.init_process_group(backend='nccl', init_method='env://')
    args.rank = dist.get_rank()
    scaler = GradScaler()
    try:
        local_rank = int(os.environ['LOCAL_RANK'])
    except:
        local_rank = dist.get_rank()
    torch.cuda.set_device(local_rank)
    gpu = f'cuda:{local_rank}'
    print(f'GPU: {gpu}')
    torch.cuda.empty_cache()
    save_path = f'{args.bytenas_path}/experiments/{args.experiment_name}'

    if not os.path.exists(save_path):
        os.makedirs(save_path, exist_ok=True)
    logging.basicConfig(filename=f'{save_path}/{args.experiment_name}.log', level=logging.INFO,
                        format='%(asctime)s - %(message)s')
    data_path = args.data_path
    print('data_path', data_path)
    print('bytenas path', args.bytenas_path)

    processor, model = build_preprocessing_and_model(args)
    print(model)
    print(f'Using {torch.cuda.device_count()} GPUs')
    model.cuda(gpu)
    if len(args.load_checkpoint) > 0:
        print(f'Load checkpoint {args.load_checkpoint}')
        checkpoint = torch.load(f'{args.load_checkpoint}', map_location='cpu')
        model.load_state_dict(checkpoint['model'], strict=True)
    else:
        print('Train from scratch')

    if args.mode == 'eval':
        if dist.get_rank() == 0:
            print('Evaluating...')
            val_dataset = RAHFDatasetCustom(data_path, 'val', processor=processor, img_len=args.input_size,
                                            val_split=10000,
                                            mask_size=args.mask_size, prompt_template=args.model, args=args)
            val_dataloader = DataLoader(dataset=val_dataset,
                                        batch_size=args.batch_size,
                                        shuffle=False,
                                        pin_memory=True,
                                        num_workers=8,
                                        sampler=None)
            thresholds = list(range(0, 200, 5))
            metrics, preds = evaluate(model, val_dataloader, gpu, None, 0, prefix='val', log_flag=False,
                                      threshold_list=thresholds)
            print(json.dumps(metrics, indent=4))
            return
    # save config to yaml
    if args.rank == 0:
        with open(f'{save_path}/config.yaml', 'w') as f:
            yaml.dump(vars(args), f)
    print('Preparing dataloader...')
    train_dataset = RAHFDatasetCustom(data_path, 'train', processor=processor, finetune=False, img_len=args.input_size,
                                      mask_size=args.mask_size,
                                      val_split=args.val_split, prompt_template=args.model, args=args)
    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)
    train_dataloader = DataLoader(dataset=train_dataset,
                                  batch_size=args.batch_size_warmup,
                                  shuffle=False,
                                  num_workers=8,
                                  pin_memory=True,
                                  sampler=train_sampler)

    val_dataset = RAHFDatasetCustom(data_path, 'val', processor=processor, img_len=args.input_size,
                                    val_split=args.val_split,
                                    mask_size=args.mask_size, prompt_template=args.model, args=args)
    # val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset)
    val_dataloader = DataLoader(dataset=val_dataset,
                                batch_size=args.batch_size,
                                # batch_size=1,   # to get finetune performance
                                shuffle=False,
                                pin_memory=True,
                                num_workers=8,
                                sampler=None)

    train_dataloader1 = DataLoader(dataset=train_dataset,
                                   batch_size=args.batch_size,
                                   shuffle=False,
                                   num_workers=8,
                                   pin_memory=True,
                                   sampler=train_sampler)

    if args.epoch > 0:
        args.iters = args.epoch * len(train_dataloader) // args.accumulate_step

    # print all trainable parameters

    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)
    # model = nn.parallel.DistributedDataParallel(model, device_ids=[gpu], broadcast_buffers=False, find_unused_parameters=True)
    model = nn.parallel.DistributedDataParallel(model, device_ids=[gpu], find_unused_parameters=True)

    # params group
    backbone_params = []
    head_params = []
    for name, param in model.named_parameters():
        if 'image_encoder' in name or 'text_encoder' in name:
            backbone_params.append(param)
        else:
            head_params.append(param)

    param_groups = [
        # backbone
        {'params': backbone_params, 'weight_decay': 1e-3,
         'lr': args.lr * args.backbone_lr_decay},
        # heads
        {'params': head_params, 'lr': args.lr, 'weight_decay': 5e-5},
    ]

    # optimizer = torch.optim.AdamW(param_groups, lr=args.lr)
    optimizer = torch.optim.AdamW(param_groups)
    # lr_lambda = lambda step: min((step+1) / 500.0, 1.0)
    # lr_lambda = lambda step: min(1.0/math.sqrt(step+1), 1.0)
    # lr_lambda = lambda step: 1.0
    # scheduler = CyclicLR(optimizer, base_lr=1e-5, max_lr=1e-3, step_size_up=400, cycle_momentum=False)
    # scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)
    scheduler = CosineAnnealingLR(optimizer, T_max=args.iters, eta_min=args.min_lr, last_epoch=-1)
    # if len(args.load_checkpoint) > 0:
    #     optimizer.load_state_dict(checkpoint['optimizer'])
    #     scheduler.load_state_dict(checkpoint['scheduler'])

    criterion = ScoreLoss(type=args.score_loss).to(gpu)
    criterion_heatmap = MaskLoss(type=args.mask_loss).to(gpu)

    def train_loop(model, train_dataloader, val_dataloader, iter_counter, epoch_counter, end_iter, accumulate_step):
        print(f"iter:{iter_counter}, epoch:{epoch_counter}, end:{end_iter}, accumlate:{accumulate_step}")
        while True:
            model.train()
            print(f'Epoch {epoch_counter}')
            train_dataloader.sampler.set_epoch(epoch_counter)
            iter_loss = [[], [], [], []]
            for batch_id, (inputs, targets) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):
                inputs = inputs.to(gpu)
                inputs_pixel_values, inputs_ids_im, inputs_ids_mis = inputs['pixel_values'].squeeze(1), inputs[
                                                                                                            'input_ids'][
                                                                                                        :, 0, :], \
                    inputs['input_ids'][:, 1, :]
                if args.fp16:
                    with autocast(dtype=torch.float16):
                        outputs_im = model(inputs_pixel_values, inputs_ids_im, need_score=True)  # implausibility
                        # implausibility heatmap
                        output_heatmap, target_heatmap = outputs_im[0].to(gpu), targets['artifact_map'].float().to(gpu)
                        loss_im = criterion_heatmap(output_heatmap, target_heatmap)

                        # implausibility score
                        output_score, target_score = outputs_im[1].to(gpu), targets['artifact_score'].float().to(gpu)
                        # get tensor from other rank

                        loss_score = criterion(output_score, target_score)
                else:
                    outputs_im = model(inputs_pixel_values, inputs_ids_im, need_score=True)  # implausibility
                    # implausibility heatmap
                    output_heatmap, target_heatmap = outputs_im[0].to(gpu), targets['artifact_map'].float().to(gpu)
                    loss_im = criterion_heatmap(output_heatmap, target_heatmap)

                    # implausibility score
                    output_score, target_score = outputs_im[1].to(gpu), targets['artifact_score'].float().to(gpu)
                    # get tensor from other rank

                    loss_score = criterion(output_score, target_score)
                # print(loss_score)

                # # get score
                # output_score = output_score.softmax(-1)
                # print(output_score[0])
                # output_score = output_score * torch.arange(5, device=output_score.device).view(1, 5)
                # print(output_score[0])
                # output_score = output_score.sum(1)
                # print(output_score[0])
                # implausibility loss
                iter_loss[0].append(loss_im.item())
                iter_loss[1].append(loss_score.item())
                loss = loss_im * args.mask_loss_weight + loss_score * args.score_loss_weight
                if args.fp16:
                    scaler.scale(loss).backward()
                else:
                    loss.backward()
                iter_loss[2].append(0)
                iter_loss[3].append(0)

                if (batch_id + 1) % accumulate_step == 0 or batch_id == len(train_dataloader):
                    torch.nn.utils.clip_grad_norm_(model.parameters(), 2.)
                    if args.fp16:
                        scaler.step(optimizer)
                        scaler.update()
                    else:
                        optimizer.step()
                    optimizer.zero_grad()
                    scheduler.step()
                    iter_counter += 1
                    dist.barrier()
                    print_log_iter(optimizer, iter_counter, iter_loss, logger)
                    iter_loss = [[], [], [], []]
                    if iter_counter >= end_iter:
                        return iter_counter, epoch_counter
            # after every epoch
            if epoch_counter % args.val_iter == 0:
                evaluate(model, val_dataloader, gpu, criterion, iter_counter, prefix='val')
                # evaluate(model, val_dataloader_all, gpu, criterion, iter_counter, prefix='all')
            if epoch_counter % args.save_iter == 0:
                save_in_training(model, optimizer, scheduler, iter_counter, save_path)
            epoch_counter += 1

    if dist.get_rank() == 0: wandb.init(project="NTIRE2025", name=args.experiment_name)
    iter_counter = 0
    epoch_counter = 0
    start_time = time.time()
    # torch.autograd.set_detect_anomaly(True)
    dist.barrier()
    if args.warmup_epoch > 0:
        if args.use_lora and len(args.load_checkpoint) < 1:
            raise ValueError('warmup stage does not support lora if checkpoint is not provided')
        print('warmup Training...')
        print('warmup stage training, freeze image&text encoder')
        set_params_trainable(model, args, stage='warmup')
        step_per_epoch = len(train_dataloader) // args.accumulate_step
        accumulate_step = args.accumulate_step * args.batch_size // args.batch_size_warmup
        iter_counter, epoch_counter = train_loop(model, train_dataloader, val_dataloader, iter_counter, epoch_counter,
                                                 step_per_epoch * args.warmup_epoch, accumulate_step)
        dist.barrier()
    print('after warmup(if have) training')
    set_params_trainable(model, args, stage='train')
    # set_norm_layers_trainable(model, True)
    del train_dataloader
    iter_counter, epoch_counter = train_loop(model, train_dataloader1, val_dataloader, iter_counter, epoch_counter,
                                             args.iters, args.accumulate_step)
    dist.barrier()
    final_save(model, optimizer, scheduler, start_time, save_path)
    dist.destroy_process_group()


def debug(args):
    args.model = 'florence2'
    processor, model = build_preprocessing_and_model(args)
    print(model)
    print_trainable_params(model)

    # train_dataset = RAHFDatasetCustom(args.data_path, 'train', processor=processor, finetune=False, img_len=args.input_size,
    #                             val_split=args.val_split)
    # for inputs, targets in train_dataset:
    #     inputs[
    #         'input_ids'] = inputs['input_ids'].unsqueeze(0)
    #     inputs_pixel_values, inputs_ids_im, inputs_ids_mis = inputs['pixel_values'].squeeze(1), inputs[
    #                                                                                                 'input_ids'][
    #                                                                                             :, 0, :], \
    #         inputs['input_ids'][:, 1, :]
    #     outputs_im = model(inputs_pixel_values, inputs_ids_im, need_score=True)


if __name__ == '__main__':
    from configs import get_args

    args = get_args()
    if args.mode == 'debug':
        debug(args)
    elif args.mode in ['train', 'eval']:
        main(args)
