# -*- coding: utf-8 -*-
"""RAHF_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CQSm0-C9TBWVDIHHyqgtfpoYC42esbTs
"""
import os

os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
import torch
import torch.nn as nn

from transformers import AutoProcessor, AutoModel, AutoConfig

from .basic_components import Residual, Attention, FeedForward
import torch.nn.functional as F


class VisionTransformer(nn.Module):
    def __init__(self, pretrained_model, new_position_embedding_weight):
        super(VisionTransformer, self).__init__()
        self.ViT = pretrained_model.vision_model
        self.new_position_embedding_weight = new_position_embedding_weight
        # 插值vit embeddings
        # self.interpolate_embeddings()
        self.load_interpolate_embeddings()

        # self.freeze = freeze
        # if self.freeze:
        #     for param in self.ViT.parameters():
        #         param.requires_grad = False
        # else:
        #     for param in self.ViT.post_layernorm.parameters():
        #         param.requires_grad = False

    def forward(self, x):
        x = self.ViT(x)
        return x

    def unfreeze(self):
        # unfreeze all parameters
        for param in self.ViT.parameters():
            param.requires_grad = True

    def freeze(self):
        # unfreeze all parameters
        for param in self.ViT.parameters():
            param.requires_grad = False
        # for param in self.ViT.parameters():
        #     param.requires_grad = True
        for param in self.ViT.post_layernorm.parameters():
            param.requires_grad = True
        # 使用siglip时需要
        # for param in self.ViT.head.parameters(): # unused
        #       param.requires_grad = False

    def load_interpolate_embeddings(self):
        with torch.no_grad():
            self.ViT.embeddings.position_embedding.weight.copy_(self.new_position_embedding_weight)

    def interpolate_embeddings(self):
        self.ViT.embeddings.position_ids = torch.arange(1025).unsqueeze(0)
        position_embedding = self.ViT.embeddings.position_embedding.weight
        cls_pos, ori_pos = position_embedding[0], position_embedding[1:]
        ori_pos = ori_pos.view(16, 16, -1).unsqueeze(0).permute(0, 3, 1, 2)

        resized_pos = F.interpolate(ori_pos, size=(32, 32), mode='bilinear')
        resized_pos = resized_pos.squeeze(0).permute(1, 2, 0).view(1024, -1)
        new_position_embedding_weight = torch.cat((cls_pos.unsqueeze(0), resized_pos), dim=0)
        new_position_embedding = nn.Embedding(1025, 1024)
        with torch.no_grad():
            new_position_embedding.weight.copy_(new_position_embedding_weight)
        self.ViT.embeddings.position_embedding = new_position_embedding


class TextEmbedding(nn.Module):
    def __init__(self, pretrained_model):
        super(TextEmbedding, self).__init__()

        # AltCLIP
        self.text_embedding = pretrained_model.text_model.roberta.embeddings
        # self.freeze = freeze
        # if self.freeze:
        #     for param in self.text_embedding.parameters():
        #         param.requires_grad = False

    def forward(self, x):
        x = self.text_embedding(x)
        return x

    def unfreeze(self):
        for param in self.text_embedding.parameters():
            param.requires_grad = True

    def freeze(self):
        for param in self.text_embedding.parameters():
            param.requires_grad = False


class LayerPair(nn.Module):
    def __init__(self, dim, hidden_dim):
        super(LayerPair, self).__init__()
        self.norm1 = nn.LayerNorm(dim)
        self.attention = Residual(Attention(dim))
        self.norm2 = nn.LayerNorm(dim)
        self.feed_forward = Residual(FeedForward(dim, hidden_dim))

    def forward(self, x):
        x = self.norm1(x)
        x = self.attention(x)
        x = self.norm2(x)
        x = self.feed_forward(x)
        return x


class SelfAttention(nn.Module):
    def __init__(self, num_layers=6, dim=768, hidden_dim=2048):
        super(SelfAttention, self).__init__()
        self.layers = nn.ModuleList([LayerPair(dim, hidden_dim) for _ in range(num_layers)])
        self.norm = nn.LayerNorm(dim)

    def forward(self, x):
        for layer in self.layers:
            x = layer(x)
        return self.norm(x)


class HeatmapPredictor(nn.Module):
    def __init__(self, conv_info=[768, 384, 384], deconv_info=[384, 384, 384, 384, 192], feature_size=32, norm='bn'):
        super(HeatmapPredictor, self).__init__()
        self.filter_size = deconv_info
        self.conv_layers = nn.Sequential(
            nn.Conv2d(in_channels=conv_info[0], out_channels=conv_info[1], kernel_size=(3, 3), stride=(1, 1),
                      padding=1),
            nn.LayerNorm([conv_info[1], feature_size, feature_size]),
            nn.ReLU(),
            nn.Conv2d(in_channels=conv_info[1], out_channels=conv_info[2], kernel_size=(3, 3), stride=(1, 1),
                      padding=1),
            nn.LayerNorm([conv_info[2], feature_size, feature_size]),
            nn.ReLU()
        )
        self.deconv_layers = nn.ModuleList([
            nn.ModuleList([
                # nn.ConvTranspose2d(in_channels=self.filter_size[i],
                #                    out_channels=self.filter_size[i + 1],
                #                    kernel_size=(3, 3),
                #                    stride=(2, 2),
                #                    padding=1, output_padding=1),
                # nn.LayerNorm([self.filter_size[i + 1], 32 * 2 ** (i + 1), 32 * 2 ** (i + 1)]),
                # nn.ReLU(),
                # nn.Conv2d(in_channels=self.filter_size[i + 1],
                #           out_channels=self.filter_size[i + 1],
                #           kernel_size=(3, 3), stride=(1, 1), padding=1),
                # nn.LayerNorm([self.filter_size[i + 1], 32 * 2 ** (i + 1), 32 * 2 ** (i + 1)]),
                # nn.ReLU(),
                nn.Conv2d(in_channels=self.filter_size[i],
                          out_channels=self.filter_size[i + 1],
                          kernel_size=(3, 3), stride=(1, 1), padding=1),
                nn.UpsamplingBilinear2d(scale_factor=2),
                nn.BatchNorm2d(self.filter_size[i + 1]) if norm == 'bn' else nn.LayerNorm(
                    [self.filter_size[i + 1], feature_size * 2 ** (i + 1), feature_size * 2 ** (i + 1)]),
                # ,
                nn.ReLU(),
            ]) for i in range(len(self.filter_size) - 1)
        ])
        self.final_layers = nn.Sequential(
            nn.Conv2d(in_channels=self.filter_size[-1], out_channels=1, kernel_size=(3, 3), stride=(1, 1), padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.conv_layers(x)
        for layer in self.deconv_layers:
            for deconv in layer:
                x = deconv(x)
        x = self.final_layers(x)
        return x


class ScorePredictor(nn.Module):
    def __init__(self, filter_info=[768, 768, 384, 128, 64], score_cls=True, flatten_size=None, linear_only=False,
                 norm='bn', feature_size=32):
        super(ScorePredictor, self).__init__()
        self.filter_size = filter_info
        self.linear_only = linear_only
        if not linear_only:
            self.conv_layers = nn.ModuleList([
                nn.ModuleList([
                    nn.Conv2d(in_channels=self.filter_size[i],
                              out_channels=self.filter_size[i + 1],
                              kernel_size=(2, 2), stride=(1, 1)),
                    nn.LayerNorm([self.filter_size[i + 1], feature_size - (i + 1),
                                  feature_size - (i + 1)]) if norm.lower() == 'ln' else nn.BatchNorm2d(
                        self.filter_size[i + 1]),
                    nn.ReLU(),
                ]) for i in range(len(self.filter_size) - 1)
            ])
        self.flatten_size = flatten_size
        if self.flatten_size is None:
            self.flatten_size = self.filter_size[-1] * (32 - (len(self.filter_size) - 1)) ** 2
        self.fc_layers = nn.Sequential(
            nn.Linear(in_features=self.flatten_size, out_features=2048),
            nn.BatchNorm1d(num_features=2048) if norm.lower() == 'bn' else nn.Identity(),
            nn.ReLU(),
            nn.Linear(in_features=2048, out_features=1024),
            nn.BatchNorm1d(num_features=1024) if norm.lower() == 'bn' else nn.Identity(),
            nn.ReLU(),
            # nn.Linear(in_features=1024, out_features=1),
            # nn.Sigmoid()
        )
        if not score_cls:
            print('binary class')
            self.fc_layers.extend([nn.Linear(in_features=1024, out_features=1),
                                   nn.Sigmoid()
                                   ])
        else:
            print('multi class')
            self.fc_layers.extend([nn.Linear(in_features=1024, out_features=5),
                                   # nn.Softmax(dim=-1)
                                   ])

    def forward(self, x):
        if not self.linear_only:
            for layers in self.conv_layers:
                for layer in layers:
                    x = layer(x)
        x = torch.flatten(x, start_dim=1)
        x = self.fc_layers(x)
        return x


class HeatmapPredictorTest(nn.Module):
    def __init__(self, conv_info=[768, 384, 384], deconv_info=[384, 384, 384, 384, 192], feature_size=32, norm='bn',
                 cls=False):
        super(HeatmapPredictorTest, self).__init__()
        self.cls = cls
        self.filter_size = deconv_info
        self.conv_layers = nn.Sequential(
            nn.Conv2d(in_channels=conv_info[0], out_channels=conv_info[1], kernel_size=(3, 3), stride=(1, 1),
                      padding=1),
            nn.LayerNorm([conv_info[1], feature_size, feature_size]) if norm.lower() == 'ln' else nn.BatchNorm2d(
                conv_info[1]),
            nn.ReLU(),
            nn.Conv2d(in_channels=conv_info[1], out_channels=conv_info[2], kernel_size=(3, 3), stride=(1, 1),
                      padding=1),
            nn.LayerNorm([conv_info[2], feature_size, feature_size]) if norm.lower() == 'ln' else nn.BatchNorm2d(
                conv_info[2]),
            nn.ReLU()
        )
        self.deconv_layers = nn.ModuleList([
            nn.ModuleList([
                # nn.ConvTranspose2d(in_channels=self.filter_size[i],
                #                    out_channels=self.filter_size[i + 1],
                #                    kernel_size=(3, 3),
                #                    stride=(2, 2),
                #                    padding=1, output_padding=1),
                # nn.LayerNorm([self.filter_size[i + 1], 32 * 2 ** (i + 1), 32 * 2 ** (i + 1)]),
                # nn.ReLU(),
                # nn.Conv2d(in_channels=self.filter_size[i + 1],
                #           out_channels=self.filter_size[i + 1],
                #           kernel_size=(3, 3), stride=(1, 1), padding=1),
                # nn.LayerNorm([self.filter_size[i + 1], 32 * 2 ** (i + 1), 32 * 2 ** (i + 1)]),
                # nn.ReLU(),
                nn.Conv2d(in_channels=self.filter_size[i],
                          out_channels=self.filter_size[i + 1],
                          kernel_size=(3, 3), stride=(1, 1), padding=1),
                nn.UpsamplingBilinear2d(scale_factor=2),
                nn.BatchNorm2d(self.filter_size[i + 1]) if norm == 'bn' else nn.LayerNorm(
                    [self.filter_size[i + 1], feature_size * 2 ** (i + 1), feature_size * 2 ** (i + 1)]),
                # ,
                nn.ReLU(),
            ]) for i in range(len(self.filter_size) - 1)
        ])
        self.label_list = torch.tensor([0, 64, 127, 180, 255]).view(-1, 5, 1, 1)

        self.final_layers = nn.Sequential(
            nn.Conv2d(in_channels=self.filter_size[-1], out_channels=1, kernel_size=(3, 3), stride=(1, 1), padding=1),
        )
        if not self.cls:
            self.final_layers = nn.Sequential(
                nn.Conv2d(in_channels=self.filter_size[-1], out_channels=1, kernel_size=(3, 3), stride=(1, 1),
                          padding=1),
                nn.Sigmoid(),
            )
        else:
            self.final_layers = nn.Sequential(
                nn.Conv2d(in_channels=self.filter_size[-1], out_channels=5, kernel_size=(3, 3), stride=(1, 1),
                          padding=1),
                nn.Softmax(dim=1)
            )

    def forward(self, x, return_softmax=False):
        x = self.conv_layers(x)
        for layer in self.deconv_layers:
            for deconv in layer:
                x = deconv(x)
        x = self.final_layers(x)
        if self.cls:
            # print('softmax for mask')
            # print(x[0, :, 0, 0])
            if return_softmax: softmax_p = x.clone()
            x = torch.sum(self.label_list.to(x.device) * x, dim=1, keepdim=True) / 255.
            if return_softmax:
                return (x, softmax_p)
        return x


class ScorePredictorTest(nn.Module):
    def __init__(self, filter_info=[768, 768, 384, 128, 64], score_cls=True, flatten_size=None, linear_only=False,
                 norm='bn', feature_size=32):
        super(ScorePredictorTest, self).__init__()
        self.filter_size = filter_info
        self.linear_only = linear_only
        self.num_class = 13
        if not linear_only:
            self.conv_layers = nn.ModuleList([
                nn.ModuleList([
                    nn.Conv2d(in_channels=self.filter_size[i],
                              out_channels=self.filter_size[i + 1],
                              kernel_size=(2, 2), stride=(1, 1)),
                    nn.LayerNorm([self.filter_size[i + 1], feature_size - (i + 1),
                                  feature_size - (i + 1)]) if norm.lower() == 'ln' else nn.BatchNorm2d(
                        self.filter_size[i + 1]),
                    nn.ReLU(),
                ]) for i in range(len(self.filter_size) - 1)
            ])
        self.flatten_size = flatten_size
        if self.flatten_size is None:
            self.flatten_size = self.filter_size[-1] * (32 - (len(self.filter_size) - 1)) ** 2
        self.fc_layers = nn.Sequential(
            nn.Linear(in_features=self.flatten_size, out_features=2048),
            nn.BatchNorm1d(num_features=2048) if norm.lower() == 'bn' else nn.Identity(),
            nn.ReLU(),
            nn.Linear(in_features=2048, out_features=1024),
            nn.BatchNorm1d(num_features=1024) if norm.lower() == 'bn' else nn.Identity(),
            nn.ReLU(),
            # nn.Linear(in_features=1024, out_features=1),
            # nn.Sigmoid()
        )
        self.label_list = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]).view(-1, 13)
        self.score_cls = score_cls
        if not score_cls:
            print('binary class')
            self.fc_layers.extend([nn.Linear(in_features=1024, out_features=1),
                                   nn.Sigmoid()
                                   ])
        else:
            print('multi class')
            self.fc_layers.extend([nn.Linear(in_features=1024, out_features=self.num_class),
                                   nn.Softmax(dim=-1)
                                   ])

    def forward(self, x, return_softmax=False):
        if not self.linear_only:
            for layers in self.conv_layers:
                for layer in layers:
                    x = layer(x)
        x = torch.flatten(x, start_dim=1)
        x = self.fc_layers(x)
        if self.score_cls:
            # print('softmax for cls')
            # print(x[0, :])
            if return_softmax:
                softmax_p = x.clone()
            x = torch.sum(self.label_list.to(x.device) * x, dim=-1)
            x = (x - 1.) / 12.
            x = x.view(x.shape[0], 1)
            if return_softmax:
                return (x, softmax_p)
        return x


class RAHF(nn.Module):
    def __init__(self, pretrained_model_path, freeze=True, score_cls=False):
        super(RAHF, self).__init__()
        # interpolate = True if 'altclip' in pretrained_model_path else False
        pretrained_config = AutoConfig.from_pretrained(pretrained_model_path)
        pretrained_config.vision_config.image_size = 448
        pretrained_model = AutoModel.from_pretrained(pretrained_model_path, config=pretrained_config,
                                                     ignore_mismatched_sizes=True)
        new_position_embedding_weight = torch.load(f"{pretrained_model_path}/new_position_embedding_weight_448.pt")
        self.image_encoder = VisionTransformer(pretrained_model, new_position_embedding_weight)
        self.text_encoder = TextEmbedding(pretrained_model)
        self.self_attention = SelfAttention(dim=1024, hidden_dim=2048)
        self.heatmap_predictor = HeatmapPredictor(conv_info=[1024, 512, 512], deconv_info=[512, 256, 128, 64, 32])
        self.score_predictor = ScorePredictor(filter_info=[1024, 1024, 512, 128, 64], score_cls=score_cls)
        if freeze:
            print('freeze image encoder and text encoder')
            self.image_encoder.freeze()
            self.text_encoder.freeze()
        else:
            print('unfreeze image encoder and text encoder')
            self.image_encoder.unfreeze()
            self.text_encoder.unfreeze()

    def forward(self, image, prompt, need_score=True):
        image_token = self.image_encoder(image).last_hidden_state
        text_token = self.text_encoder(prompt)
        x = torch.cat([image_token, text_token], dim=1)
        x = self.self_attention(x)
        feature_map = x[:, 1:1025, :].clone().view(-1, 32, 32, 1024).permute(0, 3, 1, 2)
        heatmap = self.heatmap_predictor(feature_map)

        if not need_score:
            return heatmap
        else:
            score = self.score_predictor(feature_map)
            return heatmap, score


from .florence2 import Florence2EncoderOnly

from peft import LoraConfig, get_peft_model, TaskType


class RAHFFlorence2(nn.Module):
    def __init__(self, pretrained_model_path=None, freeze=True, use_lora=True, score_head='linear', lora_rank=8,
                 mask_head='concat'):
        super(RAHFFlorence2, self).__init__()
        self.florence2 = Florence2EncoderOnly()
        self.mask_head = mask_head
        if use_lora:
            target_modules = [
                "q_proj", "o_proj", "k_proj", "v_proj", 'qkv', 'proj',
                "linear", "Conv2d", "lm_head", 'fc1', "fc2"
            ]
            lora_config = LoraConfig(r=lora_rank,
                                     lora_alpha=8,
                                     target_modules=target_modules,
                                     task_type=TaskType.FEATURE_EXTRACTION,
                                     lora_dropout=0.05,
                                     bias="none",
                                     inference_mode=False,
                                     use_rslora=True,
                                     init_lora_weights="gaussian",
                                     )
            self.florence2 = get_peft_model(self.florence2, lora_config)
        self.score_head = score_head
        c = 2048 if 'concat' in self.mask_head else 1024
        mask_cls = True if 'cls' in self.mask_head else False
        self.heatmap_predictor = HeatmapPredictorTest(conv_info=[c, 1024, 512],
                                                      deconv_info=[512, 256, 256, 128, 64, 32],
                                                      feature_size=24, norm='bn', cls=mask_cls)
        if score_head == 'linear':
            self.score_predictor = ScorePredictorTest(filter_info=[2048, 1024, 512, 128, 64], score_cls=False,
                                                      flatten_size=1024, feature_size=24, norm='bn', linear_only=True)
        elif score_head == 'linear_cls':
            self.score_predictor = ScorePredictorTest(filter_info=[2048, 1024, 512, 128, 64], score_cls=True,
                                                      flatten_size=1024, feature_size=24, norm='bn', linear_only=True)
        elif score_head == 'linear2':
            self.score_predictor = ScorePredictorTest(filter_info=[2048, 1024, 512, 128, 64], score_cls=False,
                                                      flatten_size=2048, feature_size=24, norm='bn',
                                                      linear_only=True)
        elif score_head == 'linear2_cls':
            self.score_predictor = ScorePredictorTest(filter_info=[2048, 1024, 512, 128, 64], score_cls=True,
                                                      flatten_size=2048, feature_size=24, norm='bn',
                                                      linear_only=True)
        elif score_head == 'conv':
            self.score_predictor = ScorePredictorTest(filter_info=[2048, 1024, 512, 128, 64], score_cls=False,
                                                      flatten_size=20 * 20 * 64, feature_size=24, norm='bn')
        else:
            raise NotImplementedError(f'unknown score head:{score_head}')

    def unfreeze_image_encoder(self):
        params = ['vision_tower', 'image_proj_norm']
        for name, param in self.florence2.named_parameters():
            if any([p in name for p in params]):
                param.requires_grad = True

    def forward(self, image, prompt, need_score=True, return_softmax=False):
        image_feature, feature_map = self.florence2(input_ids=prompt,
                                                    pixel_values=image)
        image_pooling_feature = image_feature[:, 0, :]
        feature_for_heatmap = feature_map[:, 1:577, :].view(-1, 24, 24, 1024).permute(0, 3, 1, 2).contiguous()
        if 'concat' in self.mask_head:
            image_feature = image_feature[:, 1:577, :].view(-1, 24, 24, 1024).permute(0, 3, 1, 2).contiguous()
            feature_for_heatmap = torch.concat([image_feature, feature_for_heatmap], dim=1)
        heatmap = self.heatmap_predictor(feature_for_heatmap, return_softmax=return_softmax)

        if not need_score:
            return heatmap
        else:
            # feature_for_score = feature_map[:, :577, :]
            if self.score_head in ['linear2', 'linear2_cls']:
                score_feature = torch.concat([image_pooling_feature, feature_map[:, 0, :]], dim=1)
            elif self.score_head in ['linear', 'linear_cls']:
                score_feature = feature_map[:, 0, :]
            elif self.score_head == 'conv':
                score_feature = feature_for_heatmap
            score = self.score_predictor(score_feature, return_softmax=return_softmax)
            return heatmap, score


def build_preprocessing_and_model(args):
    model = args.model
    if getattr(args, 'mask_head', None) is None:
        args.mask_head = 'concat'
    lora_rank = getattr(args, 'lora_rank', 8)
    if model == 'altclip':
        import os
        processor_path = os.path.join(os.path.dirname(__file__), '../', 'altclip_processor')
        model_path = os.path.join(os.path.dirname(__file__), '../', 'altclip_model')
        processor = AutoProcessor.from_pretrained(processor_path)
        model = RAHF(pretrained_model_path=model_path, freeze=False,
                     score_cls=True if 'cls' in args.score_head else False)
    elif model == 'florence2':
        model_path = 'microsoft/Florence-2-large'
        processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)
        model = RAHFFlorence2(freeze=False, use_lora=args.use_lora, lora_rank=lora_rank,
                              score_head=args.score_head, mask_head=args.mask_head)
    # elif model == 'florence2-large-ft':  # TODO: to remove
    #     processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)
    #     model = RAHFFlorence2(freeze=False, use_lora=args.use_lora,
    #                           score_head=args.score_head)
    else:
        raise NotImplementedError(f'unknown model:{model}')
    return processor, model


def set_norm_layers_trainable(model, trainable=True):
    """
    递归遍历模型的所有子模块，将 BatchNorm 和 LayerNorm 的 requires_grad 设置为 True。
    """
    for submodule in model.children():
        if isinstance(submodule, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d, nn.LayerNorm)):
            # 如果是 BatchNorm 或 LayerNorm，设置其参数的 requires_grad 为 True
            for param in submodule.parameters():
                param.requires_grad = trainable
        else:
            # 递归遍历子模块
            set_norm_layers_trainable(submodule)


def set_name_params_trainable(names: str, trainable=True):
    names = names.split(',')
    for name, param in model.named_parameters():
        if any([n in name for n in names]):
            param.requires_grad = trainable


if __name__ == "__main__":
    model = RAHF()
